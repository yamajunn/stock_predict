{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_43816\\1513312699.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  appl_data['Open'].ffill(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50/50 [==============================] - 2s 17ms/step - loss: 49.4692 - val_loss: 30.3322\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 2.7598 - val_loss: 33.7501\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.8453 - val_loss: 31.5392\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.2784 - val_loss: 27.3655\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.8061 - val_loss: 31.4156\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.7219 - val_loss: 32.8111\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.6989 - val_loss: 31.4668\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.5567 - val_loss: 30.8326\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.5000 - val_loss: 33.5866\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.5314 - val_loss: 32.7268\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4273 - val_loss: 36.8029\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.5100 - val_loss: 35.1617\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.6275 - val_loss: 33.6990\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.3740 - val_loss: 32.9383\n",
      "55/55 [==============================] - 0s 2ms/step\n",
      "Mean Squared Error: 659.0665497036152\n",
      "Root Mean Squared Error: 25.672291477459023\n"
     ]
    }
   ],
   "source": [
    "# データを読み込む\n",
    "data_dir = '../Mining_DATA/Formatted_DATA/'\n",
    "\n",
    "# csvファイルのリストを取得\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# データを格納するための辞書\n",
    "data_dict = {}\n",
    "\n",
    "# 各csvファイルを読み込む\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    data_dict[file] = df\n",
    "\n",
    "# AAPL.csvを除外して説明変数を作成\n",
    "appl_data = data_dict['AAPL.csv']\n",
    "\n",
    "# AAPL.csvのデータのOpenカラムの値を過去方向にずらす\n",
    "appl_data['Open'] = appl_data['Open'].shift(100)\n",
    "\n",
    "# NaNを前方向補完で埋める\n",
    "appl_data['Open'].ffill(inplace=True)\n",
    "\n",
    "# 同じ日付で他のCSVのDataカラムを結びつける\n",
    "merged_data = appl_data[['Date', 'Open']].copy()  # 目的変数\n",
    "\n",
    "# AAPL.csv以外のCSVファイルのDataカラムを結びつける\n",
    "for file, df in data_dict.items():\n",
    "    if file != 'AAPL.csv':\n",
    "        merged_data = pd.merge(merged_data, df[['Date', 'Open']], on='Date', suffixes=('', f'_{file[:-4]}'))\n",
    "\n",
    "merged_data.replace(0, np.nan, inplace=True)  # ゼロをNaNに変換\n",
    "merged_data.ffill(inplace=True)  # 前方向補完\n",
    "merged_data.bfill(inplace=True)  # 後方向補完\n",
    "\n",
    "# 説明変数と目的変数に分ける\n",
    "X = merged_data.drop(columns=['Date', 'Open'])  # 説明変数\n",
    "y = merged_data['Open']  # 目的変数（AAPL.csvのOpen）\n",
    "\n",
    "# データをtrainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# データを標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# モデルの作成 (ニューラルネットワーク)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(128, activation='leaky_relu'))\n",
    "model.add(Dense(256, activation='leaky_relu'))\n",
    "model.add(Dense(512, activation='leaky_relu'))\n",
    "model.add(Dense(1024, activation='leaky_relu'))\n",
    "model.add(Dense(2048, activation='leaky_relu'))\n",
    "model.add(Dense(2048, activation='leaky_relu'))\n",
    "model.add(Dense(2048, activation='leaky_relu'))\n",
    "model.add(Dense(2048, activation='leaky_relu'))\n",
    "model.add(Dense(2048, activation='leaky_relu'))\n",
    "model.add(Dense(2048, activation='leaky_relu'))\n",
    "model.add(Dense(1024, activation='leaky_relu'))\n",
    "model.add(Dense(512, activation='leaky_relu'))\n",
    "model.add(Dense(256, activation='leaky_relu'))\n",
    "model.add(Dense(128, activation='leaky_relu'))\n",
    "model.add(Dense(64, activation='leaky_relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# モデルのコンパイル\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\n",
    "\n",
    "# 早期停止のコールバックを設定\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# モデルの学習\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping]  # コールバックを追加\n",
    ")\n",
    "\n",
    "# testデータで予測を実行\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 精度評価\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 予測結果と実際の値をプロット\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Open Price')\n",
    "plt.title('Actual vs Predicted Open Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# y_predを100日分後にずらす\n",
    "y_pred_shifted = np.roll(y_pred, 100)\n",
    "\n",
    "# 予測結果と実際の値をプロット\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values, label='Actual')\n",
    "plt.plot(y_pred_shifted, label='Predicted (Shifted)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Open Price')\n",
    "plt.title('Actual vs Predicted Open Prices (Shifted)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データをプロットする\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 各株のOpen値をプロット\n",
    "for file, df in data_dict.items():\n",
    "    plt.plot(df['Date'], df['Open'], label=file[:-4])\n",
    "\n",
    "# プロットの設定\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Open Price')\n",
    "plt.title('Stock Open Prices')\n",
    "plt.legend(loc='best')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# プロットを表示\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
