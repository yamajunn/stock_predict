{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# データを保存するフォルダ\n",
    "data_dir = 'stocks/stocks/'\n",
    "# 複数のCSVファイルを読み込んで一つのDataFrameにまとめる\n",
    "all_files = glob(os.path.join(data_dir, \"*.csv\"))\n",
    "df_list = [pd.read_csv(file) for file in all_files]\n",
    "data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 日付データの型変換\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "# 各銘柄に対して一意なIDを割り当てる（銘柄名をIDにするか、もしくはファイル名からIDを生成する）\n",
    "data['Stock_ID'] = [os.path.basename(file).replace('.csv', '') for file in all_files for _ in range(len(pd.read_csv(file)))]\n",
    "\n",
    "# TFTに必要な形式に変換（通常はlong format）\n",
    "data = data[['Stock_ID', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "data = data.rename(columns={'Date': 'time_idx', 'Close': 'target'})\n",
    "\n",
    "# time_idx（時間のインデックス）を生成する\n",
    "data['time_idx'] = data.groupby('Stock_ID')['time_idx'].rank(method='dense').astype(int) - 1\n",
    "\n",
    "# 欠損値が存在するかを確認\n",
    "print(\"各カラムの欠損値数:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "# 欠損値を直前の値で補完（前方補完）\n",
    "data = data.fillna(method=\"ffill\")\n",
    "\n",
    "# 前方補完で欠損値が残る場合は後方補完も行う\n",
    "data = data.fillna(method=\"bfill\")\n",
    "\n",
    "# 補完後に再度欠損値の確認\n",
    "print(\"欠損値の補完後の確認:\")\n",
    "print(data.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 無限大の値を検出し、欠損値に置き換え\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 欠損値と同様に補完処理を行う\n",
    "data = data.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "# データセットの設定\n",
    "max_encoder_length = 30  # 過去30日間のデータをエンコード\n",
    "max_prediction_length = 7  # 7日間の予測\n",
    "\n",
    "# データセットの構築\n",
    "training = TimeSeriesDataSet(\n",
    "    data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[\"Stock_ID\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"Stock_ID\"],\n",
    "    time_varying_known_reals=[\"time_idx\", \"Open\", \"High\", \"Low\", \"Adj Close\", \"Volume\"],\n",
    "    time_varying_unknown_reals=[\"target\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data import TorchNormalizer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# バッチサイズを設定\n",
    "batch_size = 64  # 計算資源によって調整\n",
    "train_dataloader = DataLoader(training, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# TFTモデルの初期化\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # 隠れ層のサイズ\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 1週間予測する場合\n",
    "    loss=QuantileLoss(),  # Quantile Lossを使用\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"モデルには{tft.size()}個のパラメータが含まれています\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training))  # データセットのサイズを確認\n",
    "print(training[0])  # 最初のサンプルを表示して、Noneが含まれていないか確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# データセットとデータローダーの作成\n",
    "training = TimeSeriesDataSet(\n",
    "    data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[\"Stock_ID\"],\n",
    "    max_encoder_length=30,\n",
    "    max_prediction_length=7,\n",
    "    static_categoricals=[\"Stock_ID\"],\n",
    "    time_varying_known_reals=[\"time_idx\", \"Open\", \"High\", \"Low\", \"Adj Close\", \"Volume\"],\n",
    "    time_varying_unknown_reals=[\"target\"],\n",
    ")\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Noneの値をフィルタリング\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Batch is empty after filtering None values.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training, batch_size=64, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "print(len(train_dataloader))  # データローダーのサイズを確認\n",
    "for batch in train_dataloader:\n",
    "    print(batch)  # バッチの中身を確認\n",
    "    break\n",
    "# TemporalFusionTransformerインスタンスの作成\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,\n",
    "    loss=QuantileLoss(),\n",
    ")\n",
    "\n",
    "# TemporalFusionTransformerをLightningModuleとしてラップする\n",
    "class TFTLightningModel(pl.LightningModule):\n",
    "    def __init__(self, tft_model):\n",
    "        super(TFTLightningModel, self).__init__()\n",
    "        self.model = tft_model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # モデルの予測\n",
    "        y_hat = self.model(batch)\n",
    "        # 損失計算\n",
    "        loss = self.model.loss(y_hat, batch[\"target\"])\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.model.configure_optimizers()\n",
    "\n",
    "# ラップしたモデルのインスタンス作成\n",
    "wrapped_tft = TFTLightningModel(tft)\n",
    "\n",
    "# Trainerのインスタンスを作成し、トレーニングを実行\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=30,\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "# Trainerでモデルを訓練する\n",
    "trainer.fit(model=wrapped_tft, train_dataloaders=train_dataloader)\n",
    "\n",
    "# 学習済みモデルの保存\n",
    "tft.save_model(\"tft_stock_model.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
